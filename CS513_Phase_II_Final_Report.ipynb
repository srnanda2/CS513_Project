{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNA1oZ0mkjRqVMsZY6bwsDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srnanda2/CS513_Project/blob/main/CS513_Phase_II_Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Report CS 513: Phase II\n",
        "## Team 46\n",
        "\n",
        "###\n",
        "\n",
        "Soumya Nanda\t- srnanda2@illinois.edu  \n",
        "Ayush Ghosh \t-  ayushg7@illinois.edu  \n",
        "Aditi Ghosh \t- aditig4@illinois.edu\n",
        "\n",
        "Github Repo: \thttps://github.com/srnanda2/CS513_Project\n",
        "\n",
        "\n",
        "<b>Use Case (U1):</b> <i>Perform a comprehensive analysis of dish prices over time to identify trends, price ranges, and changes in pricing strategies.</i>\n",
        "\n",
        "###\n"
      ],
      "metadata": {
        "id": "oS1OWuVkzuzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZqHoXA141S4B",
        "outputId": "9669e27e-5cec-406a-ea78-a7f5e1331a54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dir and function to load a subset of preprocessed data\n",
        "raw_data_dir = '/content/drive/My Drive/CS513 Project/NYPL'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dish_df = pd.read_csv(f'{raw_data_dir}/Dish.csv')\n",
        "menu_df = pd.read_csv(f'{raw_data_dir}/Menu.csv')\n",
        "menu_item_df = pd.read_csv(f'{raw_data_dir}/MenuItem.csv')\n",
        "menu_page_df = pd.read_csv(f'{raw_data_dir}/MenuPage.csv')"
      ],
      "metadata": {
        "id": "U_bhz6fC2SuK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Description of Data Cleaning Performed\n",
        " ### High-Level Data Cleaning Steps and Rationale\n",
        "\n",
        "\n",
        "####1. Missing Value Imputation\n",
        "\n",
        "#####- We addressed missing values in several critical columns across the four data files. Specifically:\n",
        "\n",
        "\n",
        "*  Dish.csv: description, lowest_price, highest_price\n",
        "\n",
        "*  Menu.csv: name, sponsor, event, venue, place, keywords, date, currency_symbol\n",
        "\n",
        "*  MenuPage.csv: page_number\n",
        "\n",
        "*  MenuItem.csv: price, high_price, dish_id\n",
        "\n",
        "\n",
        "<b>Rationale:</b> *Missing values in critical fields like prices and descriptions can hinder meaningful analysis. Imputing or excluding these values ensures that the dataset is robust enough to support our main use case.*"
      ],
      "metadata": {
        "id": "k1L_T7cHzycl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Dish.csv: description, lowest_price, highest_price\n",
        "dish_df['description'].fillna('No description', inplace=True)\n",
        "dish_df['lowest_price'].fillna(dish_df['lowest_price'].mean(), inplace=True)\n",
        "dish_df['highest_price'].fillna(dish_df['highest_price'].mean(), inplace=True)\n",
        "\n",
        "# For Menu.csv: name, sponsor, event, venue, place, keywords, date, currency_symbol\n",
        "menu_df.fillna({'name': 'Unknown', 'sponsor': 'Unknown', 'event': 'Unknown', 'venue': 'Unknown', 'place': 'Unknown',\n",
        "                'keywords': 'None', 'date': 'Unknown', 'currency_symbol': '$'}, inplace=True)\n",
        "\n",
        "# For MenuPage.csv: page_number\n",
        "menu_page_df['page_number'].fillna(0, inplace=True)\n",
        "\n",
        "# For MenuItem.csv: price, high_price, dish_id\n",
        "menu_item_df['price'].fillna(menu_item_df['price'].mean(), inplace=True)\n",
        "menu_item_df['high_price'].fillna(menu_item_df['high_price'].mean(), inplace=True)\n",
        "menu_item_df['dish_id'].fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "3RCyduV644k_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Data Type Correction\n",
        "\n",
        "#####- We corrected data types to ensure consistency and accuracy. Specifically:\n",
        "\n",
        "\n",
        "*  Converted lowest_price and highest_price to DECIMAL(10, 2) in Dish.csv.\n",
        "\n",
        "*  Converted first_appeared and last_appeared to YEAR format in Dish.csv.\n",
        "\n",
        "*  Corrected data types for keywords, language, and location_type in Menu.csv to VARCHAR.\n",
        "\n",
        "\n",
        "*  Ensured page_number in MenuPage.csv and dish_id in MenuItem.csv are integers.\n",
        "\n",
        "\n",
        "\n",
        "<b>Rationale:</b> *Correct data types are essential for performing accurate numerical and temporal analyses, which are critical for understanding price trends and making meaningful comparisons over time (U1)*"
      ],
      "metadata": {
        "id": "-Qk8o3kk5DJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dish.csv: lowest_price and highest_price to float, first_appeared and last_appeared to YEAR\n",
        "dish_df['lowest_price'] = dish_df['lowest_price'].astype(float).round(2)\n",
        "dish_df['highest_price'] = dish_df['highest_price'].astype(float).round(2)\n",
        "dish_df['first_appeared'] = pd.to_datetime(dish_df['first_appeared'], errors='coerce').dt.year\n",
        "dish_df['last_appeared'] = pd.to_datetime(dish_df['last_appeared'], errors='coerce').dt.year\n",
        "\n",
        "# Menu.csv: keywords, language, and location_type to VARCHAR\n",
        "menu_df['keywords'] = menu_df['keywords'].astype(str)\n",
        "menu_df['language'] = menu_df['language'].astype(str)\n",
        "menu_df['location_type'] = menu_df['location_type'].astype(str)\n",
        "\n",
        "# MenuPage.csv: page_number to integer\n",
        "menu_page_df['page_number'] = menu_page_df['page_number'].astype(int)\n",
        "\n",
        "# MenuItem.csv: dish_id to integer\n",
        "menu_item_df['dish_id'] = menu_item_df['dish_id'].astype(int)\n"
      ],
      "metadata": {
        "id": "OpTxoqcV5ft8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3. Standardisation of Values:\n",
        "\n",
        "#####- Standardised values in columns that had inconsistent entries\n",
        "\n",
        "\n",
        "*  Ensured consistent formatting for first_appeared and last_appeared in Dish.csv\n",
        "\n",
        "<b>Rationale:</b> *Consistent values are crucial for temporal analyses and comparisons. Standardising these values helps in accurately tracking the historical trends of dish prices (U1)*"
      ],
      "metadata": {
        "id": "3LfqVwXz52N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dish.csv: first_appeared and last_appeared\n",
        "dish_df['first_appeared'].fillna(0, inplace=True)\n",
        "dish_df['last_appeared'].fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "d276Hrly6Mpw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4. Data Enrichment:\n",
        "\n",
        "#####- We enriched the dataset by incorporating external data sources to add context:\n",
        "\n",
        "\n",
        "*  Adjusted historical prices using 2% inflation rates to provide a real-time comparison.\n",
        "\n",
        "* Added derived columns such as average_price, price_range, and price_trend to facilitate deeper analysis.\n",
        "\n",
        "\n",
        "<b>Rationale:</b> *Enriching the dataset with additional contextual information like inflation rates helps in understanding the true value changes over time, which is essential for a comprehensive analysis of dish prices (U1)*"
      ],
      "metadata": {
        "id": "HRmxo3LO6Yih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust historical prices using inflation rates\n",
        "# Assuming a simple example with a fixed inflation rate of 2% per year\n",
        "inflation_rate = 0.02\n",
        "current_year = pd.Timestamp.now().year\n",
        "\n",
        "def adjust_for_inflation(price, year):\n",
        "    if year == 0:\n",
        "        return price\n",
        "    return price * ((1 + inflation_rate) ** (current_year - year))\n",
        "\n",
        "dish_df['adjusted_lowest_price'] = dish_df.apply(lambda row: adjust_for_inflation(row['lowest_price'], row['first_appeared']), axis=1).round(2)\n",
        "dish_df['adjusted_highest_price'] = dish_df.apply(lambda row: adjust_for_inflation(row['highest_price'], row['last_appeared']), axis=1).round(2)\n",
        "\n",
        "# Add derived columns\n",
        "menu_item_df['average_price'] = (menu_item_df['price'] + menu_item_df['high_price']) / 2\n",
        "menu_item_df['price_range'] = menu_item_df['high_price'] - menu_item_df['price']\n",
        "menu_item_df['price_trend'] = menu_item_df['high_price'] / menu_item_df['price']\n"
      ],
      "metadata": {
        "id": "GQ3QL7zX6sBy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4. Handling Duplicates:\n",
        "\n",
        "#####- Identified and removed duplicate entries in MenuItem.csv.\n",
        "\n",
        "\n",
        "<b>Rationale:</b> *Duplicate entries can skew analysis results and lead to inaccurate insights. Removing duplicates ensures data integrity and reliability of the analysis (U1)*"
      ],
      "metadata": {
        "id": "aSfFQw-j65aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Duplicates\n",
        "menu_item_df.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "5NPR-cmh7LrN"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}